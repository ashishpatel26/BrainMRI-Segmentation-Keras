{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRI_Brain_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBFduXpDIXz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-5Kcc_7-JZH",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset and Preprocessing\n",
        "Perform histogram equalization on the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3LQjheZIqU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = np.load(\"drive/My Drive/MRI_Brain_Segmentation/dataset/Dataset_final_1.npy\", allow_pickle=True)\n",
        "#x = np.load(\"drive/My Drive/MRI_Brain_Segmentation/dataset/Dataset_final_2.npy\", allow_pickle=True) \n",
        "#dataset = np.concatenate((dataset,x),axis=0)\n",
        "#x = np.load(\"drive/My Drive/MRI_Brain_Segmentation/dataset/Dataset_final_3.npy\", allow_pickle=True) \n",
        "#dataset = np.concatenate((dataset,x),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leu4R-g4KiBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def histeq(im,nbr_bins=256):\n",
        "  \"\"\"This is for image equalization\"\"\"\n",
        "  #get image histogram\n",
        "  imhist,bins = np.histogram(im.flatten(),nbr_bins,normed=True)\n",
        "   \n",
        "  cdf = imhist.cumsum() #cumulative distribution function\n",
        "  \n",
        "  cdf_m = np.ma.masked_equal(cdf,0)#mask the background voxels \n",
        "    \n",
        "  # the main step of histogram equalization\n",
        "  cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min()) \n",
        "   \n",
        "  cdf = np.ma.filled(cdf_m,0).astype('uint8') # set the removed background pixels back to 0\n",
        "\n",
        "  #use linear interpolation of cdf to find new pixel values\n",
        "    \n",
        "  # im2 = np.interp(im.flatten(),bins[:-1],cdf)/255 # this line can cause the program to fail\n",
        "  # ############################################## because it returns a float64 and run out of RAM\n",
        "  im2 = (np.interp(im.flatten(),bins[:-1],cdf)/255).astype(np.float32)\n",
        "\n",
        "  return im2.reshape(im.shape), cdf\n",
        "\n",
        "\n",
        "\n",
        "# padding to all sides of the 3D volume\n",
        "npad = ((43,43), (43,43), (43,43))\n",
        "for i in range (0, len(dataset)):  \n",
        "  dataset[i][0] = np.pad(dataset[i][0], pad_width=npad, mode='constant', constant_values=0)\n",
        "  dataset[i][1] = np.pad(dataset[i][1], pad_width=npad, mode='constant', constant_values=0)\n",
        "  #\n",
        "  #\n",
        "\n",
        "  if i == 0: # Just for the first patient\n",
        "    # plot histogram of the dataset raw values\n",
        "    # Do not display the voxels at 0 for there are too many background voxels\n",
        "    plt.hist(dataset[i][0].ravel(),256,[0.000001,np.amax(dataset[i][0])])\n",
        "    plt.show()\n",
        "    #print(\"**** Display some sample values for reference: z=125; x=125; y=[125:140] \")\n",
        "    #print(\"raw: \",dataset[i][0][125][125][125:140])\n",
        "    #print(\"label: \",dataset[i][1][125][125][125:140])\n",
        "    #print(np.shape(dataset[i][0]))\n",
        "    tmp_total = np.size(dataset[i][0])\n",
        "    #print(\"Total number of voxels in the Patient = \",tmp_total)\n",
        "    # The following is to count the number of non-zero voxels in the raw values\n",
        "    tmp_xyz=np.shape(dataset[i][0])\n",
        "    countNZ = sum(sum(sum(dataset[i][0] != 0)))\n",
        "\n",
        "    #print(\"Total number of non-zero voxels = \",countNZ)\n",
        "    \n",
        "    print(\"Next is Image Equalization\")\n",
        "\n",
        "  # Tp carry out image equalization\n",
        "  dataset[i][0],_ = histeq(dataset[i][0])\n",
        "\n",
        "\n",
        "  if i == 0: # Just for the first patient\n",
        "    # Do not display the voxels at 0 for there are too many background voxels\n",
        "    # Hence, the use of 0.000001\n",
        "    plt.hist(dataset[i][0].ravel(),256,[0.000001,np.amax(dataset[i][0])])\n",
        "    plt.show()\n",
        "    #print(\"equalize: \",dataset[i][0][125][125][125:140])\n",
        "\n",
        "\n",
        "print(\"Number of patient (Length of dataset) = \",len(dataset) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKeGvG71-X0V",
        "colab_type": "text"
      },
      "source": [
        "# Foundamental building block - Residual Network\n",
        "**buildResBlock** function returns the residual block and it is utilized in other function that stacks the residual blocks to form a larger network.\n",
        "\n",
        "Each **buildSingleResNet__** functions create the network for different input dimension, small patch, large patch or 3D voxel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNu5hJMlMNjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "Residual Block\n",
        "\"\"\"\n",
        "\n",
        "def buildResBlock(inputs, layer_type='cv',\n",
        "                  filter1=16, filter2=16, \n",
        "                  conv_size1=(3,3), conv_size2=(3,3), \n",
        "                  stride1=(1,1), stride2=(1,1), stridec=(2,2),\n",
        "                  input_size_cross=False\n",
        "                  ):\n",
        "  \n",
        "  if layer_type == 'cv':\n",
        "\n",
        "    x = layers.BatchNormalization()(inputs)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filter1, conv_size1, strides=stride1, padding='SAME')(x)\n",
        "    \n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filter2, conv_size2, strides=stride2, padding='SAME')(x)\n",
        "    \n",
        "    if input_size_cross:\n",
        "      ex = layers.Conv2D(filter2, (1,1), strides=stridec, padding='SAME')(inputs)\n",
        "      x = layers.add([x, ex])\n",
        "    else:\n",
        "      x = layers.add([x, inputs])\n",
        "      \n",
        "    return x\n",
        "\n",
        "  elif layer_type == 'cv3':\n",
        "\n",
        "    x = layers.BatchNormalization()(inputs)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv3D(filter1, conv_size1, strides=stride1, padding='SAME')(x)\n",
        "    \n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv3D(filter2, conv_size2, strides=stride2, padding='SAME')(x)\n",
        "    \n",
        "    if input_size_cross:\n",
        "      ex = layers.Conv3D(filter2, (1,1,1), strides=stridec, padding='SAME')(inputs)\n",
        "      x = layers.add([x, ex])\n",
        "    else:\n",
        "      x = layers.add([x, inputs])\n",
        "      \n",
        "    return x\n",
        "  \n",
        "  else:\n",
        "    print(\"Type Error\")\n",
        "    return None\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7PMpqj1M_3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildSingleResNetSmall():\n",
        "  inputs = layers.Input(shape=(16,16,1))\n",
        "  x = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='SAME', activation='relu')(inputs)\n",
        "  x = layers.MaxPooling2D((2, 2))(x)\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=128, filter2=128, stridec=(1,1), input_size_cross=True)\n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=128, filter2=128)\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256, stride1=(2,2), input_size_cross=True)\n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256)\n",
        "\n",
        "  #x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256, stride1=(2,2), input_size_cross=True)\n",
        "  #x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256)\n",
        "  \n",
        "  x = layers.AveragePooling2D((2, 2))(x)\n",
        "  \n",
        "  x = layers.Flatten()(x)\n",
        "  \n",
        "  network = models.Model(inputs=inputs, outputs=x)\n",
        "  return network\n",
        "\n",
        "  \n",
        "\n",
        "def buildSingleResNetLarge():\n",
        "  inputs = layers.Input(shape=(87,87,1))\n",
        "  x = layers.Conv2D(64, (7, 7), strides=(3, 3), padding='VALID', activation='relu')(inputs)\n",
        "  x = layers.MaxPooling2D((2, 2))(x)\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=128, filter2=128, stridec=(1,1), input_size_cross=True)\n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=128, filter2=128)\n",
        "  \n",
        "  x = layers.MaxPooling2D((2, 2))(x)\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256, stride1=(2,2), input_size_cross=True)\n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256)\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256, stride1=(2,2), input_size_cross=True)\n",
        "  x = buildResBlock(inputs=x, layer_type='cv', filter1=256, filter2=256)\n",
        "  \n",
        "  x = layers.AveragePooling2D((2, 2))(x)\n",
        "  \n",
        "  x = layers.Flatten()(x)\n",
        "  \n",
        "  network = models.Model(inputs=inputs, outputs=x)\n",
        "  return network\n",
        "\n",
        "  \n",
        "\n",
        "def buildSingleResNetCube():\n",
        "  \n",
        "  inputs = layers.Input(shape=(26,26,26,1))\n",
        "  \n",
        "  x = layers.Conv3D(64, (3, 3, 3), strides=(2, 2, 2), padding='SAME', activation='relu')(inputs)\n",
        "  \n",
        "  x = layers.MaxPooling3D((2, 2, 2))(x)\n",
        "  \n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv3', conv_size1=(3,3,3), conv_size2=(3,3,3), \n",
        "                    filter1=128, filter2=128, stride1=(1,1,1), stride2=(1,1,1), stridec=(1,1,1), input_size_cross=True)\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv3', conv_size1=(3,3,3), conv_size2=(3,3,3), \n",
        "                    filter1=128, filter2=128, stride1=(1,1,1), stride2=(1,1,1))\n",
        "\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv3', conv_size1=(3,3,3), conv_size2=(3,3,3), \n",
        "                    filter1=256, filter2=256, stride1=(2,2,2), stride2=(1,1,1), stridec=(2,2,2), input_size_cross=True)\n",
        "  \n",
        "  x = buildResBlock(inputs=x, layer_type='cv3', conv_size1=(2,2,2), conv_size2=(2,2,2), \n",
        "                    filter1=256, filter2=256, stride1=(1,1,1), stride2=(1,1,1))\n",
        "\n",
        "  x = layers.AveragePooling3D((2, 2, 2))(x)\n",
        "  \n",
        "  x = layers.Flatten()(x)\n",
        "  \n",
        "  network = models.Model(inputs=inputs, outputs=x)\n",
        "  \n",
        "  return network\n",
        "\n",
        "  \n",
        "\n",
        "#res_cube = buildSingleResNetCube()\n",
        "#res_cube.summary()\n",
        "#plot_model(res_cube, to_file='drive/My Drive/MRI_Brain_Segmentation/resnet_diagram.png',show_shapes=True)\n",
        "\n",
        "#res_small = buildSingleResNetSmall()\n",
        "#res_small.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFAIu1o0VMLT",
        "colab_type": "code",
        "outputId": "20f2eb9b-7eb0-43e6-a954-fa0a2f5b45b8",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "def buildFullNetwork():\n",
        "  cube = layers.Input(shape=(26,26,26,1))\n",
        "  cube_i = buildSingleResNetCube()(cube)\n",
        "  x = layers.Dropout(rate=0.5)(cube_i)\n",
        "  x = layers.Dense(135, activation='softmax')(x)\n",
        "  network = models.Model(inputs=cube, outputs=x)\n",
        "  return network\n",
        "\n",
        "resnet = buildFullNetwork()\n",
        "resnet.summary()\n",
        "#plot_model(resnet, to_file='drive/My Drive/MRI_Brain_Segmentation/resnet_diagram_highlv.png',show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 26, 26, 26, 1)     0         \n",
            "_________________________________________________________________\n",
            "model_3 (Model)              (None, 256)               5301120   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 135)               34695     \n",
            "=================================================================\n",
            "Total params: 5,335,815\n",
            "Trainable params: 5,333,127\n",
            "Non-trainable params: 2,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyBHwLDB_7BR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwTE21-U_MRa",
        "colab_type": "text"
      },
      "source": [
        "# **Model Compilation and Training**\n",
        "\n",
        "During training, pixels that contain useful info (non background) are randomly sampled from the dataset and then the surrounding pixels of the chosen pixels are extracted to form a voxel of size 26x26x26. The sampled voxels are then fed into the model for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrBMo2Q5nTAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = optimizers.Adam(lr=2e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=1e-6, amsgrad=False)\n",
        "resnet.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143_wQu8zS6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the overall number of epochs per training session of 15 patients\n",
        "T_epochs = 1\n",
        "train_batch_size = 32\n",
        "samples_size = 1000\n",
        "vald_size = 200\n",
        "test_size = samples_size - vald_size\n",
        "samples_epochs = 1\n",
        "total_voxel_sample = 1000000\n",
        "imgH = 342\n",
        "imgW = 342\n",
        "layerSize = imgH*imgW\n",
        "\n",
        "weight_path = \"drive/My Drive/MRI_Brain_Segmentation/model/resnet_cube_26_3.h5\"\n",
        "\n",
        "#reload weights that have been saved by the previous training session\n",
        "#\n",
        "#resnet.load_weights(\"drive/My Drive/MRI_Brain_Segmentation/resnet_cube_26_2.h5\")\n",
        "#\n",
        "#print(\"Model Restored\")\n",
        "train_hist_acc = []\n",
        "train_hist_val = []\n",
        "\n",
        "print(\"Start Training\")\n",
        "stime = time.time()\n",
        "\n",
        "\n",
        "try:\n",
        "  for epoch in range(T_epochs):\n",
        "    correct = 0\n",
        "    iter = 0\n",
        "    #define lists to append the data for training to vectorize the input     \n",
        "    t7=[] #voxel\n",
        "    t8=[] #ground truth\n",
        "\n",
        "    for i in range(0,len(dataset)):\n",
        "      #total number of elements in the image\n",
        "\n",
        "      #print(\"\\n Train Patient Number \" + str(i))\n",
        "      print(\"\\n Train Loop Number \" + str(i))\n",
        "      #Sample predefined number of voxels from each patient.\n",
        "      for j in range (0,total_voxel_sample):\n",
        "        value = 0\n",
        "        pat = random.randint(0,len(dataset)-1)\n",
        "        total = np.size(dataset[pat][0])\n",
        "        raw = dataset[pat][0]\n",
        "          \n",
        "        #only select non-background voxels for training\n",
        "        while(value==0):\n",
        "          voxel = random.randint(0,total-1)\n",
        "          z_layer = (voxel//layerSize)\n",
        "          row = (voxel%layerSize)//imgH\n",
        "          col = (voxel%layerSize)%imgW\n",
        "          value = dataset[pat][1][z_layer][row][col]\n",
        "\n",
        "        #extract 3D images needed for that pixel\n",
        "        #volume is 26x26x26\n",
        "        vol = raw[z_layer-13:z_layer+13,row-13:row+13,col-13:col+13]\n",
        "        vol = np.reshape(vol, (26,26,26,1))\n",
        "\n",
        "        #one-hot encode the output value (label) for training\n",
        "        # The range of value/label is [1,134]\n",
        "        output = keras.utils.to_categorical(value, num_classes=135)\n",
        "        \n",
        "        #append the data to the list for training\n",
        "        t7.append(vol)\n",
        "        t8.append(output)\n",
        "          \n",
        "        #Collect and train every certain samples.\n",
        "        if((j+1)%samples_size == 0):\n",
        "          x_train = np.array(t7)\n",
        "          y_train = np.array(t8)\n",
        "\n",
        "          fit_log = resnet.fit(x_train[0:test_size], y_train[0:test_size], \n",
        "                               epochs=samples_epochs, batch_size=train_batch_size, verbose=1,\n",
        "                               validation_data=(x_train[test_size:], y_train[test_size:]))\n",
        "\n",
        "          train_hist_acc.append(fit_log.history['accuracy'])\n",
        "          train_hist_val.append(fit_log.history['val_accuracy'])\n",
        "\n",
        "          #reset the lists\n",
        "          t7=[]; t8=[]\n",
        "\n",
        "          #Backup training weights after 1 patient\n",
        "          resnet.save_weights(weight_path)\n",
        "\n",
        "    #END of the 2 FOR loops \n",
        "    print(\"\\n Training Completed: Time Taken %s s\" % (time.time()-stime))\n",
        "    print('Epoch', epoch+1, 'completed out of',T_epochs)\n",
        "\n",
        "  #END of the 3 FOR loops \n",
        "  print(\"Training Complete and Saving Model with \" + str(j+1) +\" Iterations per patient\")\n",
        "  #Save weights after training completes\n",
        "  resnet.save_weights(weight_path)\n",
        "  print(\"Saved model to disk\")\n",
        "  print(\"All training completed !\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "  print(\"Training Interrupted Saving Model with \" + str((j+1)) +\" Iterations/patient\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngXiLw57ACKP",
        "colab_type": "text"
      },
      "source": [
        "Plotting the training & validation accuracy after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upeI4h3KPrx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_hist_acc[:2500])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.savefig('drive/My Drive/MRI_Brain_Segmentation/train_acc.png', dpi=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC3ZQMsuQOou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_hist_val[:2500], 'r')\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.savefig('drive/My Drive/MRI_Brain_Segmentation/train_val_acc.png', dpi=200)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}